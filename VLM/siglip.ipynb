{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SIGLIP_VISION_CONFIG(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        hidden_size = 768,\n",
    "        ffn_2 = 3072,\n",
    "        num_hidden_layer = 12,\n",
    "        num_channels = 3,\n",
    "        image_size = 224,\n",
    "        patch_size = 16,\n",
    "        layer_norm = 1e-6,\n",
    "        attention_dropout = 0.0,\n",
    "        num_attn_heads = 12):\n",
    "\n",
    "        super.__init__()\n",
    "        self.hidden_size = hidden_size,\n",
    "        self.ffn_2 = ffn_2,\n",
    "        self.num_hidden_layer = num_hidden_layer,\n",
    "        self.num_channels = num_channels,\n",
    "        self.image_size = image_size,\n",
    "        self.patch_size = patch_size,\n",
    "        self.layer_norm = layer_norm,\n",
    "        self.attention_dropout = attention_dropout,\n",
    "        self.num_heads = num_attn_heads\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SIGLIP_VISION_EMBEDDING(nn.Module):\n",
    "    def __init__(self,config:SIGLIP_VISION_CONFIG):\n",
    "        self.config = config\n",
    "        self.embed_size = config.hidden_size\n",
    "        self.image_size = config.image_size\n",
    "        self.patch_size = config.patch_size\n",
    "\n",
    "        self.num_patches = (self.image_size/self.patch_size) *  (self.image_size/self.patch_size)\n",
    "        self.pos_embeddings = nn.Embedding(num_embeddings=self.num_patches,embedding_dim=self.embed_size)\n",
    "        self.patch_embeddings = nn.Conv2d(in_channels=self.config.num_channels,out_channels=self.config.hidden_size,kernel_size=self.patch_size,stride=self.patch_size,padding=None)\n",
    "\n",
    "        self.register_buffer(\n",
    "            \"postions_ids\",\n",
    "            torch.arange(self.num_patches).expand(-1,1),\n",
    "            persistent=False\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self,pixel_values):\n",
    "        batch_size,num_channels,height,width = pixel_values.shape\n",
    "        patch_embeds = self.patch_embeddings(pixel_values) # [Batch_Size, Embed_Dim, Num_Patches_H, Num_Patches_W] \n",
    "        patch_embeds = patch_embeds.flatten(2)# [Batch_Size, Embed_Dim, Num_Patches_H * Num_Patches_W]\n",
    "        positions = self.postions_ids[:,:self.num_patches]\n",
    "        pos_embds = self.pos_embeddings(positions)\n",
    "\n",
    "        final_embeddings = pos_embds + patch_embeds\n",
    "        return final_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SIGLIP_VISION_ATTENTION(nn.Module):\n",
    "    def __init__(self,config:SIGLIP_VISION_CONFIG, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.config = config\n",
    "        self.K = nn.Linear(in_features=config.hidden_size,out_features=config.hidden_size)\n",
    "        self.Q = nn.Linear(in_features=config.hidden_size,out_features=config.hidden_size)\n",
    "        self.V = nn.Linear(in_features=config.hidden_size,out_features=config.hidden_size)\n",
    "\n",
    "        self.O_proj = nn.Linear(in_features=config.hidden_size,out_features=config.hidden_size)\n",
    "        self.head_dim = self.config.hidden_size/self.config.num_heads\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self,hidden_states):\n",
    "        batch_size,seq_len,dim = hidden_states.size()\n",
    "        query_states = self.Q(hidden_states) #[batch,seq_len,dim]@[dim,dim] = [batch,seq_len,dim]\n",
    "        key_states = self.K(hidden_states) #[batch,seq_len,dim]@[dim,dim] = [batch,seq_len,dim]\n",
    "        value_states = self.V(hidden_states) #[batch,seq_len,dim]@[dim,dim] = [batch,seq_len,dim]\n",
    "\n",
    "        key_states = key_states.view(batch_size,seq_len,self.config.num_heads,(self.config.hidden_size/self.config.num_heads)).transpose(1,2)#[batch,n_heads,seq_len,head_dim]\n",
    "        query_states = query_states.view(batch_size,seq_len,self.config.num_heads,(self.config.hidden_size/self.config.num_heads)).transpose(1,2)#[batch,n_heads,seq_len,head_dim]\n",
    "        value_states = value_states.view(batch_size,seq_len,self.config.num_heads,(self.config.hidden_size/self.config.num_heads)).transpose(1,2)#[batch,n_heads,seq_len,head_dim]\n",
    "        qkT = query_states @ key_states.transpose(2,3) / torch.sqrt(self.head_dim)#[batch,n_heads,seq_len,seq_len]\n",
    "\n",
    "        qkT = torch.nn.functional.softmax(qkT,dim=-1)\n",
    "        final_boss = qkT @ value_states#[batch,n_heads,seq_len,head_dim]\n",
    "        final_boss = final_boss.reshape(batch_size,seq_len,self.config.num_heads,self.head_dim)\n",
    "        final_boss = final_boss.reshape(batch_size,seq_len,self.config.hidden_size)\n",
    "        final_boss = self.O_proj(final_boss)#[batch,seq_len,dim]\n",
    "        return final_boss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SIGLIP_FFN(nn.Module):\n",
    "    def __init__(self,config:SIGLIP_VISION_CONFIG ,*args, **kwargs):\n",
    "        self.config = config\n",
    "        self.ffn1 = nn.Linear(in_features=config.hidden_size,out_features=config.ffn_2)\n",
    "        self.ffn2 = nn.Linear(in_features=config.ffn_2,out_features = config.hidden_size)\n",
    "        super().__init__(*args, **kwargs)\n",
    "    def forward(hidden_features,self):\n",
    "        out1 = self.ffn1(hidden_features)\n",
    "        out1 = nn.functional.gelu(out1,approximate='tanh')\n",
    "        out2 = self.ffn2(out1)\n",
    "        return out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SIGLIP_ENCODER_BLOCK(nn.Module):\n",
    "    def __init__(self, config:SIGLIP_VISION_CONFIG,*args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.config = config\n",
    "        self.self_attn = SIGLIP_VISION_ATTENTION(config)\n",
    "        self.layerNorm1 = nn.LayerNorm(config.hidden_size,eps=1e-6)\n",
    "        self.ffnBlock = SIGLIP_FFN(config=config)\n",
    "        self.layerNorm2 = nn.LayerNorm(config.hidden_size,eps=1e-6)\n",
    "    def forward(self,hidden_states):\n",
    "        residual_state = hidden_states,\n",
    "        hidden_states = self.layerNorm1(hidden_states)\n",
    "        hidden_states = self.self_attn(hidden_states)\n",
    "        hidden_states = hidden_states + residual_state\n",
    "        residual_state = hidden_states\n",
    "\n",
    "        hidden_states = self.layerNorm2(hidden_states)\n",
    "        hidden_states = self.ffnBlock(hidden_states)\n",
    "        hidden_states = hidden_states + residual_state\n",
    "\n",
    "        return hidden_states\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SIGlIP_ENCODER(nn.Module):\n",
    "    def __init__(self,config:SIGLIP_VISION_CONFIG, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.config = config\n",
    "        self.blocks = nn.ModuleList(\n",
    "            SIGLIP_ENCODER_BLOCK(config) for _ in range(config.num_hidden_layer)\n",
    "        )\n",
    "    def forward(self,hidden_states):\n",
    "        input_embeds = hidden_states\n",
    "\n",
    "        for layer in self.blocks:\n",
    "            hidden_states = layer(input_embeds)\n",
    "\n",
    "        return hidden_states    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SIGLIP_TRANSFORMER(nn.Module):\n",
    "    def __init__(self,config:SIGLIP_VISION_CONFIG, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.embedding = SIGLIP_VISION_EMBEDDING(config)\n",
    "        self.encoder_blocks = SIGlIP_ENCODER(config=config)\n",
    "        self.post_layer_norm = nn.LayerNorm(config.hidden_size,eps = 1e-6)\n",
    "    def forward(self,pixel_values):\n",
    "        hidden_states = self.embedding(pixel_values)   \n",
    "        hidden_states = self.encoder_blocks(hidden_states)\n",
    "        final_state = self.post_layer_norm(hidden_states)\n",
    "        return final_state   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiglipVisionModel(nn.Module):\n",
    "\n",
    "    def __init__(self, config: SIGLIP_VISION_CONFIG):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.vision_model = SIGLIP_TRANSFORMER(config)\n",
    "\n",
    "    def forward(self, pixel_values):\n",
    "        # [Batch_Size, Channels, Height, Width] -> [Batch_Size, Num_Patches, Embed_Dim]\n",
    "        return self.vision_model(pixel_values=pixel_values) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
