{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math \n",
    "from dataclasses import dataclass\n",
    "from tokenizers import Tokenizer\n",
    "from pathlib import Path\n",
    "from transformers import AutoModelForCausalLM,AutoTokenizer\n",
    "import wandb\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "##parameters\n",
    "BATCH_SIZE = 128\n",
    "beta = 2\n",
    "lr = 5e-5\n",
    "gamma = 1.2\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimplePO(nn.Module):\n",
    "    def __init__(self,policy_model,gamma,beta,tokenizer):\n",
    "        super().__init__()\n",
    "        self.policy_model = policy_model\n",
    "        self.gamma = gamma\n",
    "        self.beta = beta\n",
    "    def SimplePreferenceOptimizationLoss(self,pair):\n",
    "        self.preferred_reponse = pair[\"chosen\"]\n",
    "        self.rejected_response = pair[\"rejected\"]\n",
    "\n",
    "\n",
    "        self.pref_log_sft = F.log_softmax(self.policy_model(**self.preferred_reponse),dim=-1)\n",
    "        self.pref_log_sft = torch.gather(self.pref_log_sft,dim=-1,index=self.preferred_reponse['input_ids'].unsqueeze(-1)).squeeze(1)\n",
    "        self.pref_log_sft = self.pref_log_sft * self.preferred_response['attention_mask']\n",
    "        self.pref_log_sft = torch.sum(self.pref_log_sft,dim = -1)\n",
    "\n",
    "        self.rej_log_sft = F.log_softmax(self.policy_model(**self.rejected_reponse),dim=-1)\n",
    "        self.rej_log_sft = torch.gather(self.rej_log_sft,dim=-1,index=self.rejected_response['input_ids'].unsqueeze(-1)).squeeze(1)\n",
    "        self.rej_log_sft = self.rej_log_sft * self.rejected_response['attention_mask']\n",
    "        self.rej_log_sft = torch.sum(self.win_log_sft,dim = -1)\n",
    "\n",
    "\n",
    "\n",
    "        self.norm_contraint_pref = self.pref_log_sft / torch.sum(self.preferred_reponse[\"attention_mask\"],dim=-1)\n",
    "        self.norm_contraint_rej = self.rej_log_sft / torch.sum(self.rejected_response[\"attention_mask\"],dim=-1)\n",
    "\n",
    "        self.diff = self.norm_contraint_pref - self.norm_contraint_rej\n",
    "\n",
    "        loss_func = -F.logsigmoid(\n",
    "                self.beta(self.diff) - self.gamma\n",
    "        )\n",
    "        return loss_func\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SPO_COLLATE(batch):\n",
    "    mereged_preffered_responses = []\n",
    "    mereged_rejected_responses = []\n",
    "\n",
    "    for pair in batch:\n",
    "        preferred_prompt_response = \"Instruction :\" + pair[\"instruction\"] + \"\\n\" + \"Output:\" + pair[\"chosen_response\"] \n",
    "        rejected_prompt_response = \"Instruction :\" + pair[\"instruction\"] + \"\\n\" + \"Output:\" + pair[\"rejected_response\"] \n",
    "\n",
    "\n",
    "\n",
    "        mereged_rejected_responses.append(rejected_prompt_response)\n",
    "        mereged_preffered_responses.append(preferred_prompt_response)\n",
    "\n",
    "\n",
    "        tokenized_preffered_response_with_prompt = tokenizer(mereged_preffered_responses,max_length = 1024,padding = \"longest\",trunation = True,return_tensors = \"pt\").to(device)\n",
    "        tokenized_rejected_response_with_prompt = tokenizer(mereged_rejected_responses,max_length = 1024,padding = \"longest\",trunation = True,return_tensors = \"pt\").to(device)\n",
    "\n",
    "\n",
    "\n",
    "        return {\n",
    "            \"preffered_tokens\" : tokenized_preffered_response_with_prompt,\n",
    "            \"rejeted_tokens\" : tokenized_rejected_response_with_prompt\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'batch_size' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DataLoader\n\u001b[0;32m----> 2\u001b[0m train_dataloader \u001b[38;5;241m=\u001b[39m DataLoader(batch_size\u001b[38;5;241m=\u001b[39m\u001b[43mbatch_size\u001b[49m,collate_fn\u001b[38;5;241m=\u001b[39mSPO_COLLATE,shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      3\u001b[0m val_loader \u001b[38;5;241m=\u001b[39m DataLoader(batch_size\u001b[38;5;241m=\u001b[39mbatch_size,collate_fn\u001b[38;5;241m=\u001b[39mSPO_COLLATE,shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'batch_size' is not defined"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "train_dataloader = DataLoader(batch_size=batch_size,collate_fn=SPO_COLLATE,shuffle=True)\n",
    "val_loader = DataLoader(batch_size=batch_size,collate_fn=SPO_COLLATE,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "280b85a334c940ffab618d9b1064c512",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/659 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "611927520dd44681a1a837ac53a003b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/988M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df93513db7764beaa9b9ff9e647220a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/242 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "policy_model = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen2-0.5B-Instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b83579e8ed10472c9cd53ad42a08d683",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.29k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d33432655684f9c8e02a8af547f5407",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/2.78M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f4187643c2d47d898afa78322add9f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/1.67M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c4c4a938f4a404a9f000161fdab650a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/7.03M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2-0.5B-Instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# policy_model.eval()\n",
    "prompt = \"Explain the concept of reinforcement learning in simple words.\"\n",
    "\n",
    "# Tokenize\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "# Generate response\n",
    "with torch.no_grad():\n",
    "    outputs = policy_model(\n",
    "        **inputs\n",
    "        \n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.modeling_outputs.CausalLMOutputWithPast"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[6.0498e-06, 2.2551e-06, 1.2591e-06,  ..., 8.0986e-09,\n",
       "          8.1163e-09, 8.0831e-09],\n",
       "         [6.4469e-08, 1.5519e-07, 3.9755e-09,  ..., 6.6247e-11,\n",
       "          6.6269e-11, 6.6318e-11],\n",
       "         [2.7299e-08, 1.0857e-06, 1.0422e-08,  ..., 3.1422e-10,\n",
       "          3.1385e-10, 3.1436e-10],\n",
       "         ...,\n",
       "         [9.5905e-07, 2.5847e-08, 8.0646e-09,  ..., 1.6673e-12,\n",
       "          1.6654e-12, 1.6668e-12],\n",
       "         [3.4998e-04, 5.9411e-06, 1.9451e-06,  ..., 5.5332e-11,\n",
       "          5.5433e-11, 5.5435e-11],\n",
       "         [2.0611e-07, 8.0198e-10, 5.2417e-09,  ..., 1.1033e-11,\n",
       "          1.1041e-11, 1.1044e-11]]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.softmax(outputs.logits,dim = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 11, 151936])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 11, 1])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs['input_ids'].unsqueeze(-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 11])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs['attention_mask'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4387efa854144d23ba66b3a8c812a687",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/8.62k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5033483ca10844bbabc563b9e5fac861",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)-00000-of-00001-9dffc9d46d32c335.parquet:   0%|          | 0.00/110M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3f9eaed65f14b03a32429bedcb04b7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/63619 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##loading datasets\n",
    "from datasets import load_dataset, Dataset\n",
    "\n",
    "train_dataset = load_dataset(\"argilla/ultrafeedback-binarized-preferences\", split=\"train\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_split = train_dataset.train_test_split(test_size=0.2, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_val_split['train']\n",
    "test_dataset = train_val_split['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['source', 'instruction', 'chosen_response', 'rejected_response', 'chosen_avg_rating', 'rejected_avg_rating', 'chosen_model'],\n",
       "    num_rows: 50895\n",
       "})"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['source', 'instruction', 'chosen_response', 'rejected_response', 'chosen_avg_rating', 'rejected_avg_rating', 'chosen_model'],\n",
       "    num_rows: 12724\n",
       "})"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
