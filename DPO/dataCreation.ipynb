{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import json\n",
    "\n",
    "def query_model(prompt, model=\"llama3.2:1b\", url=\"http://localhost:11434/api/chat\"):\n",
    "    data = {\n",
    "        \"model\": model,\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ],\n",
    "        \"options\": {\n",
    "            \"seed\": 123,\n",
    "            \"temperature\": 1\n",
    "        }\n",
    "    }\n",
    "    # print(data)\n",
    "\n",
    "    payload = json.dumps(data).encode(\"utf-8\")\n",
    "\n",
    "    request = urllib.request.Request(url, data=payload, method=\"POST\")\n",
    "    request.add_header(\"Content-Type\", \"application/json\")\n",
    "\n",
    "    response_data = \"\"\n",
    "    with urllib.request.urlopen(request) as response:\n",
    "        while True:\n",
    "            line = response.readline().decode(\"utf-8\")\n",
    "            if not line:\n",
    "                break\n",
    "            response_json = json.loads(line)\n",
    "            response_data += response_json[\"message\"][\"content\"]\n",
    "\n",
    "    return response_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'llama3.2:1b', 'messages': [{'role': 'user', 'content': 'what is your name'}], 'options': {'seed': 123, 'temperature': 1}}\n"
     ]
    }
   ],
   "source": [
    "result = query_model(\"what is your name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm an artificial intelligence model known as Llama. Llama stands for \"Large Language Model Meta AI.\"\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path \n",
    "\n",
    "json_file = Path(\"/Users/777bhavyagoyal/Developer/llmfromscratch/instruction-data.json\")\n",
    "\n",
    "with open(json_file,\"r\") as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': 'Evaluate the following phrase by transforming it into the spelling given.',\n",
       " 'input': 'freind --> friend',\n",
       " 'output': 'The spelling of the given phrase \"freind\" is incorrect, the correct spelling is \"friend\".'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1100"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_input(entry):\n",
    "    instruction_text = (\n",
    "        f\"Below is an instruction that describes a task. Write a response that \"\n",
    "        f\"appropriately completes the request.\"\n",
    "        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
    "    )\n",
    "\n",
    "    input_text = f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
    "    instruction_text + input_text\n",
    "\n",
    "    return instruction_text + input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Evaluate the following phrase by transforming it into the spelling given.\n",
      "\n",
      "### Input:\n",
      "freind --> friend\n"
     ]
    }
   ],
   "source": [
    "print(format_input(data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset response:\n",
      ">> The spelling of the given phrase \"freind\" is incorrect, the correct spelling is \"friend\".\n",
      "\n",
      "polite response:\n",
      "{'model': 'llama3.2:1b', 'messages': [{'role': 'user', 'content': 'Given the input `Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nEvaluate the following phrase by transforming it into the spelling given.\\n\\n### Input:\\nfreind --> friend` and correct output `The spelling of the given phrase \"freind\" is incorrect, the correct spelling is \"friend\".`, slightly rewrite the output to be more polite.Keep the modification minimal.Only return return the generated response and nothing else.'}], 'options': {'seed': 123, 'temperature': 1}}\n",
      ">> \"I'll take a closer look at the phrase 'freind' and help you find its correct spelling.\"\n",
      "\n",
      "Dataset response:\n",
      ">> He goes to the park every day.\n",
      "\n",
      "polite response:\n",
      "{'model': 'llama3.2:1b', 'messages': [{'role': 'user', 'content': 'Given the input `Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nEdit the following sentence for grammar.\\n\\n### Input:\\nHe go to the park every day.` and correct output `He goes to the park every day.`, slightly rewrite the output to be more polite.Keep the modification minimal.Only return return the generated response and nothing else.'}], 'options': {'seed': 123, 'temperature': 1}}\n",
      ">> He goes to the park every day.\n",
      "\n",
      "Dataset response:\n",
      ">> 45 kilometers is 45000 meters.\n",
      "\n",
      "polite response:\n",
      "{'model': 'llama3.2:1b', 'messages': [{'role': 'user', 'content': 'Given the input `Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nConvert 45 kilometers to meters.` and correct output `45 kilometers is 45000 meters.`, slightly rewrite the output to be more polite.Keep the modification minimal.Only return return the generated response and nothing else.'}], 'options': {'seed': 123, 'temperature': 1}}\n",
      ">> \"I can help with that. To convert 45 kilometers to meters, I'll multiply it by 1000, since there are 1000 meters in a kilometer.\" \n",
      "\n",
      "45 kilometers is 45000 meters.\n",
      "\n",
      "Dataset response:\n",
      ">> Although it was raining, they went for a walk.\n",
      "\n",
      "polite response:\n",
      "{'model': 'llama3.2:1b', 'messages': [{'role': 'user', 'content': \"Given the input `Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nRewrite this sentence to start with 'Although': Despite the rain, they went for a walk.` and correct output `Although it was raining, they went for a walk.`, slightly rewrite the output to be more polite.Keep the modification minimal.Only return return the generated response and nothing else.\"}], 'options': {'seed': 123, 'temperature': 1}}\n",
      ">> Although it was raining, they went for a walk.\n",
      "\n",
      "Dataset response:\n",
      ">> 1, 4, 9, 16, 25, 36, 49, 64, 81, 100.\n",
      "\n",
      "polite response:\n",
      "{'model': 'llama3.2:1b', 'messages': [{'role': 'user', 'content': 'Given the input `Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nWhat are the first 10 square numbers?` and correct output `1, 4, 9, 16, 25, 36, 49, 64, 81, 100.`, slightly rewrite the output to be more polite.Keep the modification minimal.Only return return the generated response and nothing else.'}], 'options': {'seed': 123, 'temperature': 1}}\n",
      ">> 1, 4, 9, 16, 25, 36, 49, 64, 81, 100.\n"
     ]
    }
   ],
   "source": [
    "import random \n",
    "\n",
    "for entry in data[:5]:\n",
    "    politeness = random.choice([\"polite\",\"impolite\"])\n",
    "    prompt = (\n",
    "        f\"Given the input `{format_input(entry)}` \"\n",
    "        f\"and correct output `{entry['output']}`, \"\n",
    "        f\"slightly rewrite the output to be more {politeness}.\"\n",
    "        \"Keep the modification minimal.\"\n",
    "        \"Only return return the generated response and nothing else.\"\n",
    "    )\n",
    "    print(\"\\nDataset response:\")\n",
    "    print(\">>\", entry['output'])\n",
    "    print(f\"\\n{politeness} response:\")\n",
    "    print(\">>\", query_model(prompt))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "GROQ_API_KEY = \"YOUR_API_KEY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting groq\n",
      "  Downloading groq-0.18.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/777bhavyagoyal/miniconda3/lib/python3.12/site-packages (from groq) (4.8.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/777bhavyagoyal/miniconda3/lib/python3.12/site-packages (from groq) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/777bhavyagoyal/miniconda3/lib/python3.12/site-packages (from groq) (0.28.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/777bhavyagoyal/miniconda3/lib/python3.12/site-packages (from groq) (2.10.4)\n",
      "Requirement already satisfied: sniffio in /Users/777bhavyagoyal/miniconda3/lib/python3.12/site-packages (from groq) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.10 in /Users/777bhavyagoyal/miniconda3/lib/python3.12/site-packages (from groq) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/777bhavyagoyal/miniconda3/lib/python3.12/site-packages (from anyio<5,>=3.5.0->groq) (3.7)\n",
      "Requirement already satisfied: certifi in /Users/777bhavyagoyal/miniconda3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->groq) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/777bhavyagoyal/miniconda3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->groq) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/777bhavyagoyal/miniconda3/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/777bhavyagoyal/miniconda3/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /Users/777bhavyagoyal/miniconda3/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->groq) (2.27.2)\n",
      "Downloading groq-0.18.0-py3-none-any.whl (121 kB)\n",
      "Installing collected packages: groq\n",
      "Successfully installed groq-0.18.0\n"
     ]
    }
   ],
   "source": [
    "!pip install groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from groq import  Groq\n",
    "client = Groq(\n",
    "    api_key=GROQ_API_KEY\n",
    ")\n",
    "def run_groq(prompt, client, model = 'mixtral-8x7b-32768', system_prompt = None):\n",
    "\n",
    "\n",
    "    messages = []\n",
    "    \n",
    "    if system_prompt:\n",
    "        messages.append(\n",
    "            {\n",
    "                \"role\":\"system\",\n",
    "                \"content\":system_prompt\n",
    "            }\n",
    "        )\n",
    "\n",
    "    messages.append(\n",
    "        {\n",
    "            \"role\":\"user\",\n",
    "            \"content\":prompt\n",
    "        }\n",
    "    )  \n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0.0,\n",
    "        seed=123,\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello world! I'm glad to see that my code is working as expected. If you have any questions or need assistance with a specific topic, feel free to ask. I'm here to help!\""
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"Respond with 'hello world' if you got this message.\"\n",
    "run_groq(prompt, client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "from tqdm import tqdm\n",
    "\n",
    "def generate_model_responses(json_data):\n",
    "\n",
    "    for i, entry in enumerate(tqdm(json_data,desc=\"Writing entries\")):\n",
    "        politeness = random.choice([\"polite\",\"rude\"])\n",
    "        prompt = (\n",
    "            f\"Given the input `{format_input(entry)}` \"\n",
    "            f\"and correct output `{entry['output']}`, \"\n",
    "            f\"slightly rewrite the output to be more {politeness}.\"\n",
    "            \"Keep the modification minimal.\"\n",
    "            \"Only return return the generated response and nothing else.\"\n",
    "        )\n",
    "        response = query_model(prompt)\n",
    "        \n",
    "        if politeness == 'polite':\n",
    "            json_data[i][\"chosen\"] = response\n",
    "            json_data[i][\"rejected\"] = entry[\"output\"]\n",
    "\n",
    "        else:\n",
    "            json_data[i][\"chosen\"] = entry[\"output\"]\n",
    "            json_data[i][\"rejected\"]  = response    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Writing entries: 100%|██████████| 1100/1100 [08:43<00:00,  2.10it/s]\n"
     ]
    }
   ],
   "source": [
    "generate_model_responses(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': 'Explain the primary function of the human heart.',\n",
       " 'input': '',\n",
       " 'output': 'The primary function of the human heart is to pump blood throughout the body, delivering oxygen and nutrients to tissues and removing carbon dioxide and other wastes.',\n",
       " 'chosen': 'The primary function of the human heart is to pump blood throughout the body, delivering oxygen and nutrients to tissues and removing carbon dioxide and other wastes.',\n",
       " 'rejected': '```python\\ndef explain_primary_function():\\n    primary_function = \"The human heart is a muscular organ that pumps blood throughout the body, delivering oxygen and nutrients to tissues and removing carbon dioxide and other wastes.\"\\n    return corrected_output = \"Ugh, really? Fine. The human heart pumps blood. Duh.\"\\n\\n# Test the function\\nprint(explain_primary_function())\\n```'}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[990]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"instruction-data-with-preference.json\", \"w\") as file:\n",
    "    json.dump(data, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def instr_prompt_no_input(ins, outp):\n",
    "\n",
    "    sys_prompt = \"You are a helpful, precise but picky assistant for checking the quality of a given instruction.\"\n",
    "    prompt_template = \"[Instruction]\\n{ins}\\n\\n[The Start of Answer]\\n{outp}\\n\\n[The End of Answer]\\n\\n[System]\\n{criteria}\\n\\n\"\n",
    "    criteria = \"We would like you to answer several questions related to the quality of a given instruction. \\n\" + \\\n",
    "                \"1. Why this instruction is not good? First analyse the instruction based on Complexity of the Topic, Level of Detail Required, Knowledge Required, Ambiguity of the Instruction and Logical Reasoning or Problem-Solving Involved. \\n\" + \\\n",
    "                \"Then analyse why this answer is not good for the given instruction? Analyse based on the Helpfulness, Relevance, Accuracy and Level of Details. \\n\" + \\\n",
    "                \"Finally analyse why this bad instruction lead to a bad answer. \" +\\\n",
    "                \"2. Based on the reason you provided, generate a new and complete instruction which is complex and difficult to answer directly. \" + \\\n",
    "                \"Make sure the new instruction is relevent but independent to the original instruction, which can be answered without knowing the original instruction, put the new instruction in the format of [New Instruction] your instruction [End]\" +\\\n",
    "                \"3. Answer the newly generated instruction as detailed as possible, in the format of [New Answer] your answer [End] \\n\"\n",
    "    prompt = prompt_template.format(\n",
    "        ins=ins, outp=outp, criteria=criteria\n",
    "    )\n",
    "    return sys_prompt, prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "entry = data[2]\n",
    "\n",
    "system_prompt, prompt = instr_prompt_no_input(ins=entry[\"instruction\"], outp=entry[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Instruction]\n",
      "Convert 45 kilometers to meters.\n",
      "\n",
      "[The Start of Answer]\n",
      "45 kilometers is 45000 meters.\n",
      "\n",
      "[The End of Answer]\n",
      "\n",
      "[System]\n",
      "We would like you to answer several questions related to the quality of a given instruction. \n",
      "1. Why this instruction is not good? First analyse the instruction based on Complexity of the Topic, Level of Detail Required, Knowledge Required, Ambiguity of the Instruction and Logical Reasoning or Problem-Solving Involved. \n",
      "Then analyse why this answer is not good for the given instruction? Analyse based on the Helpfulness, Relevance, Accuracy and Level of Details. \n",
      "Finally analyse why this bad instruction lead to a bad answer. 2. Based on the reason you provided, generate a new and complete instruction which is complex and difficult to answer directly. Make sure the new instruction is relevent but independent to the original instruction, which can be answered without knowing the original instruction, put the new instruction in the format of [New Instruction] your instruction [End]3. Answer the newly generated instruction as detailed as possible, in the format of [New Answer] your answer [End] \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. The instruction \"Convert 45 kilometers to meters\" is not complex, does not require a high level of detail, and does not involve problem-solving or logical reasoning. It is a straightforward conversion that requires basic knowledge of units of measurement.\n",
      "\n",
      "The answer \"45 kilometers is 45000 meters\" is good because it is accurate, relevant, and provides the required level of detail. However, it could be improved by explaining the conversion process or providing additional context.\n",
      "\n",
      "The bad instruction did not lead to a bad answer, but it did not encourage a complete or informative response.\n",
      "\n",
      "2. [New Instruction] Explain the relationship between the metric system and the imperial system of measurement, including the historical context and the advantages and disadvantages of each system. [End]\n",
      "\n",
      "3. [New Answer] The metric system and the imperial system are two different systems of measurement that originated in France and England, respectively. The metric system is based on powers of ten, making it easy to convert between units. For example, 1 kilometer is equal to 1000 meters, and 1 meter is equal to 100 centimeters. The imperial system, on the other hand, is based on customary units that are not based on powers of ten. For example, 1 mile is equal to 1760 yards, and 1 yard is equal to 3 feet.\n",
      "\n",
      "The metric system is widely used in science and international commerce, while the imperial system is primarily used in the United States. The metric system is considered more logical and consistent, while the imperial system is often criticized for its complexity and lack of standardization. However, the imperial system has historical significance and is deeply ingrained in American culture.\n",
      "\n",
      "In conclusion, the metric system and the imperial system are two different systems of measurement that have their own advantages and disadvantages. While the metric system is more widely used and considered more logical, the imperial system has historical significance and cultural value.\n"
     ]
    }
   ],
   "source": [
    "output = run_groq(prompt=prompt, client=client, system_prompt=system_prompt)\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
